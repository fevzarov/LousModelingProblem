{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lous' Modeling Problem\n",
    "\n",
    "\n",
    "#### Assignment\n",
    "The company is interested in doing a marketing campaign for a product they wish to sell to existing customers. They have asked you to give them some insights into what **characteristics** of the customers are important to determine whether they will buy this product. \n",
    "\n",
    "\n",
    "#### Data\n",
    "The data in data.csv has 100,000 observations on customers. The columns are R and V1 – V30.\n",
    "-\tV1-V30: customer characteristics in February 2018\n",
    "-\tR: money spent on product if customer bought the product in April 2018 and 0 otherwise. \n",
    "\n",
    "\n",
    "#### Approaches\n",
    "\n",
    "###### I. Econometrics Approach\n",
    "\n",
    "In estimating consumer spend, a traditional econometrics approach would utilize a two-step regression approach where:\n",
    "1. The first stage will be a probit model for a binary spend vs. no spend behavior will be estimated and \n",
    "2. The second step will be linear regression model for a customer spend given that they spent.\n",
    "\n",
    "There are other models that econometricians may consider. For instance, we can consider a Tobit model, a model that Fahzy has utilized for his dissertation:\n",
    "\n",
    "> Abdul-Rahman, M. (2008). The demand for physical activity: an application of Grossman's health demand model to the elderly population. (Electronic Thesis or Dissertation). Retrieved from https://etd.ohiolink.edu/pg_10?0::NO:10:P10_ACCESSION_NUM:osu1199127215 \n",
    "\n",
    "However, ideally, these approach require that econometricians to have elaborate background on research issues and available variables. So, we will approach the posed research question from a Machine Learning angle.\n",
    "\n",
    "###### II. Machine Learning Approach\n",
    "\n",
    "We will be focussing on the posed research question, which is \n",
    "> \"what **characteristics** of the customers are important to determine whether they will buy this product\"?\n",
    "\n",
    "The posed research question is not concerned about how much a buyer spend.  Instead, we are concerned about consumers buy or not. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Packages\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Dimension: (100000, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.669044</td>\n",
       "      <td>1.332046</td>\n",
       "      <td>-0.383623</td>\n",
       "      <td>58.203268</td>\n",
       "      <td>2.516582</td>\n",
       "      <td>-0.063320</td>\n",
       "      <td>47.187762</td>\n",
       "      <td>0.050729</td>\n",
       "      <td>-3.556211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224468</td>\n",
       "      <td>1.732377</td>\n",
       "      <td>4.118886</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>3.469034</td>\n",
       "      <td>61.629681</td>\n",
       "      <td>0.058782</td>\n",
       "      <td>56.154209</td>\n",
       "      <td>11.777673</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625058</td>\n",
       "      <td>4.083644</td>\n",
       "      <td>2.500723</td>\n",
       "      <td>0.285155</td>\n",
       "      <td>31.284113</td>\n",
       "      <td>47.512823</td>\n",
       "      <td>0.101458</td>\n",
       "      <td>35.196478</td>\n",
       "      <td>81.645561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.885436</td>\n",
       "      <td>-1.545734</td>\n",
       "      <td>-2.284548</td>\n",
       "      <td>-200.012461</td>\n",
       "      <td>-0.046499</td>\n",
       "      <td>-19.956440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.907402</td>\n",
       "      <td>-4.157230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850447</td>\n",
       "      <td>-0.769063</td>\n",
       "      <td>1.164243</td>\n",
       "      <td>3.792408</td>\n",
       "      <td>-0.003194</td>\n",
       "      <td>10.892589</td>\n",
       "      <td>0.547955</td>\n",
       "      <td>-0.017424</td>\n",
       "      <td>3.889439</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1  V2  V3  V4   V5  V6  V7   V8  V9  V10 ...        V22       V23  \\\n",
       "0  1.0   1   0   1  1.0   0   1  1.0   0    1 ...   2.669044  1.332046   \n",
       "1  0.0   1   1   0  1.0   1   0  1.0   1    0 ...   0.224468  1.732377   \n",
       "2  0.0   1   1   0  1.0   1   0  NaN   1    0 ...   0.625058  4.083644   \n",
       "3  0.0   0   0   0  0.0   0   0  0.0   0    0 ...  -2.885436 -1.545734   \n",
       "4  0.0   0   1   0  0.0   1   1  0.0   1    0 ...   0.850447 -0.769063   \n",
       "\n",
       "        V24         V25        V26        V27        V28        V29  \\\n",
       "0 -0.383623   58.203268   2.516582  -0.063320  47.187762   0.050729   \n",
       "1  4.118886    0.029545   3.469034  61.629681   0.058782  56.154209   \n",
       "2  2.500723    0.285155  31.284113  47.512823   0.101458  35.196478   \n",
       "3 -2.284548 -200.012461  -0.046499 -19.956440        NaN  -4.907402   \n",
       "4  1.164243    3.792408  -0.003194  10.892589   0.547955  -0.017424   \n",
       "\n",
       "         V30    R  \n",
       "0  -3.556211  0.0  \n",
       "1  11.777673  0.0  \n",
       "2  81.645561  0.0  \n",
       "3  -4.157230  0.0  \n",
       "4   3.889439  0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data Reading\n",
    "spend_data = pd.read_csv('data.csv')\n",
    "\n",
    "print \"Original Dataset Dimension:\",spend_data.shape\n",
    "spend_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Data Cleaning\n",
    "\n",
    "### Converting consumer spend into buy (1) vs. not buy (0)\n",
    "spend_data['R'] = (spend_data['R']>0).astype(int)\n",
    "\n",
    "### We assume that the data are cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UNIVARIATE STATISTICS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>94812.0</td>\n",
       "      <td>0.345652</td>\n",
       "      <td>0.475583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.353140</td>\n",
       "      <td>0.477948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.366660</td>\n",
       "      <td>0.481895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.354280</td>\n",
       "      <td>0.478297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>94861.0</td>\n",
       "      <td>0.330188</td>\n",
       "      <td>0.470283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.334800</td>\n",
       "      <td>0.471923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.343860</td>\n",
       "      <td>0.474997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>94926.0</td>\n",
       "      <td>0.335556</td>\n",
       "      <td>0.472187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.342350</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.329910</td>\n",
       "      <td>0.470183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>17.783855</td>\n",
       "      <td>50.827240</td>\n",
       "      <td>-0.772476</td>\n",
       "      <td>-0.260634</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>7.256562</td>\n",
       "      <td>2.638056e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>19.323027</td>\n",
       "      <td>62.867176</td>\n",
       "      <td>-0.832701</td>\n",
       "      <td>-0.253954</td>\n",
       "      <td>-0.005626</td>\n",
       "      <td>7.034796</td>\n",
       "      <td>1.100220e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>169.620603</td>\n",
       "      <td>6515.731692</td>\n",
       "      <td>-0.999908</td>\n",
       "      <td>-0.270893</td>\n",
       "      <td>-0.002896</td>\n",
       "      <td>5.391247</td>\n",
       "      <td>1.569347e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>124.699564</td>\n",
       "      <td>3831.467879</td>\n",
       "      <td>-0.999679</td>\n",
       "      <td>-0.267555</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>5.475745</td>\n",
       "      <td>9.405100e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>32.786589</td>\n",
       "      <td>229.324490</td>\n",
       "      <td>-0.961159</td>\n",
       "      <td>-0.253210</td>\n",
       "      <td>-0.004784</td>\n",
       "      <td>6.142557</td>\n",
       "      <td>2.560015e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>2.891258</td>\n",
       "      <td>-11.869796</td>\n",
       "      <td>-1.562390</td>\n",
       "      <td>-0.277067</td>\n",
       "      <td>1.724082</td>\n",
       "      <td>1.249694e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>35126.0</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>2.865302</td>\n",
       "      <td>-11.064883</td>\n",
       "      <td>-1.556467</td>\n",
       "      <td>-0.288929</td>\n",
       "      <td>1.754431</td>\n",
       "      <td>1.213076e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>2.835069</td>\n",
       "      <td>-10.670182</td>\n",
       "      <td>-1.574072</td>\n",
       "      <td>-0.296816</td>\n",
       "      <td>1.754021</td>\n",
       "      <td>1.184741e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>-0.001027</td>\n",
       "      <td>2.840099</td>\n",
       "      <td>-10.892609</td>\n",
       "      <td>-1.581377</td>\n",
       "      <td>-0.296773</td>\n",
       "      <td>1.746710</td>\n",
       "      <td>1.182148e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>2.747659</td>\n",
       "      <td>-8.087127</td>\n",
       "      <td>-1.608929</td>\n",
       "      <td>-0.317319</td>\n",
       "      <td>1.873795</td>\n",
       "      <td>8.266548e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>2.831434</td>\n",
       "      <td>-10.610960</td>\n",
       "      <td>-1.591741</td>\n",
       "      <td>-0.299238</td>\n",
       "      <td>1.767556</td>\n",
       "      <td>1.125188e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>94954.0</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>2.794588</td>\n",
       "      <td>-9.396044</td>\n",
       "      <td>-1.600597</td>\n",
       "      <td>-0.310477</td>\n",
       "      <td>1.804648</td>\n",
       "      <td>9.856323e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>2.850814</td>\n",
       "      <td>-11.603235</td>\n",
       "      <td>-1.584152</td>\n",
       "      <td>-0.296654</td>\n",
       "      <td>1.752022</td>\n",
       "      <td>1.224229e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>2.933960</td>\n",
       "      <td>-13.005732</td>\n",
       "      <td>-1.537852</td>\n",
       "      <td>-0.257822</td>\n",
       "      <td>1.679422</td>\n",
       "      <td>1.445618e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.152965</td>\n",
       "      <td>97.195538</td>\n",
       "      <td>-1436.957335</td>\n",
       "      <td>-3.907526</td>\n",
       "      <td>-0.025247</td>\n",
       "      <td>5.341700</td>\n",
       "      <td>1.425994e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.323778</td>\n",
       "      <td>103.312256</td>\n",
       "      <td>-1742.910148</td>\n",
       "      <td>-3.845565</td>\n",
       "      <td>-0.022947</td>\n",
       "      <td>5.188181</td>\n",
       "      <td>2.023244e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.180752</td>\n",
       "      <td>93.239705</td>\n",
       "      <td>-1540.711386</td>\n",
       "      <td>-3.945927</td>\n",
       "      <td>-0.026531</td>\n",
       "      <td>5.442494</td>\n",
       "      <td>1.510104e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>94896.0</td>\n",
       "      <td>1.012439</td>\n",
       "      <td>66.259817</td>\n",
       "      <td>-521.187603</td>\n",
       "      <td>-4.147670</td>\n",
       "      <td>-0.030863</td>\n",
       "      <td>6.439678</td>\n",
       "      <td>6.036710e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V29</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.061797</td>\n",
       "      <td>117.153535</td>\n",
       "      <td>-1897.897519</td>\n",
       "      <td>-3.779552</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>4.825685</td>\n",
       "      <td>3.250453e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V30</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.897445</td>\n",
       "      <td>185.994822</td>\n",
       "      <td>-3858.562932</td>\n",
       "      <td>-3.441825</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>4.012091</td>\n",
       "      <td>4.643087e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.055350</td>\n",
       "      <td>0.228663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count        mean          std          min       25%       50%  \\\n",
       "V1    94812.0    0.345652     0.475583     0.000000  0.000000  0.000000   \n",
       "V2   100000.0    0.353140     0.477948     0.000000  0.000000  0.000000   \n",
       "V3   100000.0    0.366660     0.481895     0.000000  0.000000  0.000000   \n",
       "V4   100000.0    0.354280     0.478297     0.000000  0.000000  0.000000   \n",
       "V5    94861.0    0.330188     0.470283     0.000000  0.000000  0.000000   \n",
       "V6   100000.0    0.334800     0.471923     0.000000  0.000000  0.000000   \n",
       "V7   100000.0    0.343860     0.474997     0.000000  0.000000  0.000000   \n",
       "V8    94926.0    0.335556     0.472187     0.000000  0.000000  0.000000   \n",
       "V9   100000.0    0.342350     0.474498     0.000000  0.000000  0.000000   \n",
       "V10  100000.0    0.329910     0.470183     0.000000  0.000000  0.000000   \n",
       "V11  100000.0   17.783855    50.827240    -0.772476 -0.260634 -0.005666   \n",
       "V12  100000.0   19.323027    62.867176    -0.832701 -0.253954 -0.005626   \n",
       "V13  100000.0  169.620603  6515.731692    -0.999908 -0.270893 -0.002896   \n",
       "V14  100000.0  124.699564  3831.467879    -0.999679 -0.267555 -0.003277   \n",
       "V15  100000.0   32.786589   229.324490    -0.961159 -0.253210 -0.004784   \n",
       "V16  100000.0   -0.000332     2.891258   -11.869796 -1.562390 -0.277067   \n",
       "V17   35126.0    0.010280     2.865302   -11.064883 -1.556467 -0.288929   \n",
       "V18  100000.0    0.000133     2.835069   -10.670182 -1.574072 -0.296816   \n",
       "V19  100000.0   -0.001027     2.840099   -10.892609 -1.581377 -0.296773   \n",
       "V20  100000.0    0.002564     2.747659    -8.087127 -1.608929 -0.317319   \n",
       "V21  100000.0    0.002403     2.831434   -10.610960 -1.591741 -0.299238   \n",
       "V22   94954.0    0.002398     2.794588    -9.396044 -1.600597 -0.310477   \n",
       "V23  100000.0    0.000641     2.850814   -11.603235 -1.584152 -0.296654   \n",
       "V24  100000.0    0.000137     2.933960   -13.005732 -1.537852 -0.257822   \n",
       "V25  100000.0    1.152965    97.195538 -1436.957335 -3.907526 -0.025247   \n",
       "V26  100000.0    1.323778   103.312256 -1742.910148 -3.845565 -0.022947   \n",
       "V27  100000.0    1.180752    93.239705 -1540.711386 -3.945927 -0.026531   \n",
       "V28   94896.0    1.012439    66.259817  -521.187603 -4.147670 -0.030863   \n",
       "V29  100000.0    1.061797   117.153535 -1897.897519 -3.779552 -0.019113   \n",
       "V30  100000.0    1.897445   185.994822 -3858.562932 -3.441825 -0.006059   \n",
       "R    100000.0    0.055350     0.228663     0.000000  0.000000  0.000000   \n",
       "\n",
       "          75%           max  \n",
       "V1   1.000000  1.000000e+00  \n",
       "V2   1.000000  1.000000e+00  \n",
       "V3   1.000000  1.000000e+00  \n",
       "V4   1.000000  1.000000e+00  \n",
       "V5   1.000000  1.000000e+00  \n",
       "V6   1.000000  1.000000e+00  \n",
       "V7   1.000000  1.000000e+00  \n",
       "V8   1.000000  1.000000e+00  \n",
       "V9   1.000000  1.000000e+00  \n",
       "V10  1.000000  1.000000e+00  \n",
       "V11  7.256562  2.638056e+02  \n",
       "V12  7.034796  1.100220e+03  \n",
       "V13  5.391247  1.569347e+06  \n",
       "V14  5.475745  9.405100e+05  \n",
       "V15  6.142557  2.560015e+04  \n",
       "V16  1.724082  1.249694e+01  \n",
       "V17  1.754431  1.213076e+01  \n",
       "V18  1.754021  1.184741e+01  \n",
       "V19  1.746710  1.182148e+01  \n",
       "V20  1.873795  8.266548e+00  \n",
       "V21  1.767556  1.125188e+01  \n",
       "V22  1.804648  9.856323e+00  \n",
       "V23  1.752022  1.224229e+01  \n",
       "V24  1.679422  1.445618e+01  \n",
       "V25  5.341700  1.425994e+03  \n",
       "V26  5.188181  2.023244e+03  \n",
       "V27  5.442494  1.510104e+03  \n",
       "V28  6.439678  6.036710e+02  \n",
       "V29  4.825685  3.250453e+03  \n",
       "V30  4.012091  4.643087e+03  \n",
       "R    0.000000  1.000000e+00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Univariate Statistics\n",
    "\n",
    "print \"\\nUNIVARIATE STATISTICS\"\n",
    "spend_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "R           \n",
       "0      94465\n",
       "1       5535"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crosstab breakdown for spend vs. no spend \n",
    "# is consistent with 0.05535 or 5.535%\n",
    "r_count = pd.crosstab(index = spend_data[\"R\"],columns=\"count\") \n",
    "r_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data**\n",
    "\n",
    "There are various ways to deal with missing data. For this analysis, I removed observations with missing data. A quick look into univariate statistics, the statistics did not seem to change much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = spend_data.dropna()\n",
    "# df1.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Splitting**\n",
    "\n",
    "There are various ways to deal with missing data. For this analysis, I removed observations with missing data. A quick look into univariate statistics, the statistics did not seem to change much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24158, 30)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X Features\n",
    "features_list = \\\n",
    "['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10',\n",
    " 'V11','V12','V13','V14','V15','V16','V17','V18','V19','V20',\n",
    " 'V21','V22','V23','V24','V25','V26','V27','V28','V29','V30']\n",
    "\n",
    "# All rows and the feature_list' columns\n",
    "X = df1.loc[:, features_list]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24158L,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y Features; response vector\n",
    "y = df1.R\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                stratify=y, \n",
    "                                                test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ideal Number of Features**\n",
    "\n",
    "We utilized SelectKBest and GridSearchCV to arrive at an ideal number of selected features for this Machine Learning analysis. Based on this analysis, the ideal number of features is 15. If we follow this recommendation strictly, we should go with features with top 15 SelectKBest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ideal Features: {'kbest__k': 15}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "kbest = SelectKBest(f_classif)\n",
    "pipeline = Pipeline([('kbest', kbest), ('lr', LogisticRegression())])\n",
    "grid_search = GridSearchCV(pipeline, {'kbest__k': [11,12,13,14,15,16,17,18,19,20]})\n",
    "#grid_search.fit(features, labels)\n",
    "grid_search.fit(X, y)\n",
    "print \"Number of Ideal Features:\", grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 best features: ['V23', 'V22', 'V21', 'V20', 'V26', 'V25', 'V29', 'V11', 'V17', 'V2', 'V19', 'V5', 'V9', 'V8', 'V28']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('V23', 4730.5822651442013),\n",
       " ('V20', 3877.8488848645566),\n",
       " ('V17', 3805.9849686890761),\n",
       " ('V29', 3730.13556851763),\n",
       " ('V11', 2832.7792965229623),\n",
       " ('V8', 2751.5496881091253),\n",
       " ('V2', 2712.4367429901886),\n",
       " ('V5', 2624.5805116746651),\n",
       " ('V26', 2428.3500892250895),\n",
       " ('V28', 1635.7702487342374),\n",
       " ('V22', 1029.0736308810842),\n",
       " ('V19', 1027.1115706600735),\n",
       " ('V25', 974.59853370891437),\n",
       " ('V21', 226.97325075854147),\n",
       " ('V9', 207.74334284090659)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Univariate Feature Selection\n",
    "import sklearn.feature_selection\n",
    "\n",
    "knum=15\n",
    "\n",
    "k_best = sklearn.feature_selection.SelectKBest(k=knum)\n",
    "k_best.fit(X, y)\n",
    "scores = k_best.scores_\n",
    "unsorted_pairs = zip(features_list[1:], scores)\n",
    "sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "k_best_features = dict(sorted_pairs[:knum])\n",
    "print knum,\"best features: {0}\\n\".format(k_best_features.keys())\n",
    "k_best_features\n",
    "\n",
    "import operator\n",
    "sorted(k_best_features.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal number of predictors is 15 and they are listed above. Using appropiate Machine Learning and Statistical techniques, we can utilize these 15 variables to arrive at the best prediction model. \n",
    "\n",
    "In the next section, we shared two Machine Learning examples with an analysis on how modifying parameters of the same Machine Learning technique (i.e. Support Vector Machine or SVM) arrived at different prediction performance. \n",
    "\n",
    "**Estimating with a Variety of Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Totals: 1644\n",
      "Acc = 0.784\n",
      "Prec = 0.212\n",
      "Rec = 0.980\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[4389 1296]\n",
      " [   7  348]]\n"
     ]
    }
   ],
   "source": [
    "### Example 1. Naive Bayes\n",
    "\n",
    "features_list = \\\n",
    "['V23','V20','V17','V29','V11','V8','V2','V5','V26','V28','V22','V19','V25','V21','V9']\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X, y,\n",
    "                                                stratify=y, \n",
    "                                                test_size=0.25)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "accuracy = accuracy_score(predict, labels_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print \"Prediction Totals:\", sum(predict) \n",
    "print \"Acc =\",(\"{0:.3f}\".format(acc))\n",
    "print \"Prec =\",(\"{0:.3f}\".format(prec))\n",
    "print \"Rec =\",(\"{0:.3f}\".format(recall))\n",
    "\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.001 sigmoid 365 0.953 0.600 0.617 \n",
      "\n",
      "\n",
      "Confusion Matrix [0 v. 1]: \n",
      "[[5539  146]\n",
      " [ 136  219]]\n"
     ]
    }
   ],
   "source": [
    "### Example 2. Support Vector Machine (SVM)\n",
    "\n",
    "features_list = \\\n",
    "['V23','V20','V17','V29','V11','V8','V2','V5','V26','V28','V22','V19','V25','V21','V9']\n",
    "\n",
    "# Test Size\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X, y,\n",
    "                                                stratify=y, \n",
    "                                                test_size=0.25)\n",
    "ccc = 10 # C\n",
    "ggg = 0.001  # gamma_list \n",
    "svmpar = 'sigmoid' # svm_param = ['rbf', 'sigmoid']; kernel; rbf the fastest\n",
    "\n",
    "clf = SVC(kernel=svmpar, C = ccc, gamma=ggg)\n",
    "clf.fit(features_train, labels_train)\n",
    "predict = clf.predict(features_test)\n",
    "acc = accuracy_score(labels_test, predict)\n",
    "prec = precision_score(labels_test, predict)\n",
    "recall = recall_score(labels_test, predict)\n",
    "\n",
    "print ccc, ggg, svmpar,sum(predict),(\"{0:.3f}\".format(acc)), \\\n",
    "(\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n",
    "print \"\\nConfusion Matrix [0 v. 1]: \\n\",confusion_matrix(labels_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C | gamma | svmpar | n_pred | acc | prec | recall \n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FA279J\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.01 1 sigmoid 10 0.940 0.000 0.000 \n",
      "\n",
      "0.01 0.1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.01 0.1 sigmoid 3 0.941 0.000 0.000 \n",
      "\n",
      "0.01 0.01 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.01 0.01 sigmoid 0 0.941 0.000 0.000 \n",
      "\n",
      "0.01 0.001 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.01 0.001 sigmoid 139 0.932 0.295 0.115 \n",
      "\n",
      "0.01 0.0001 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.01 0.0001 sigmoid 232 0.923 0.267 0.175 \n",
      "\n",
      "0.1 1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.1 1 sigmoid 325 0.909 0.197 0.180 \n",
      "\n",
      "0.1 0.1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.1 0.1 sigmoid 315 0.902 0.124 0.110 \n",
      "\n",
      "0.1 0.01 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.1 0.01 sigmoid 332 0.914 0.250 0.234 \n",
      "\n",
      "0.1 0.001 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "0.1 0.001 sigmoid 317 0.890 0.016 0.014 \n",
      "\n",
      "0.1 0.0001 rbf 29 0.945 0.862 0.070 \n",
      "\n",
      "0.1 0.0001 sigmoid 331 0.912 0.230 0.214 \n",
      "\n",
      "1 1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "1 1 sigmoid 342 0.907 0.202 0.194 \n",
      "\n",
      "1 0.1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "1 0.1 sigmoid 364 0.896 0.126 0.130 \n",
      "\n",
      "1 0.01 rbf 8 0.941 0.375 0.008 \n",
      "\n",
      "1 0.01 sigmoid 350 0.905 0.186 0.183 \n",
      "\n",
      "1 0.001 rbf 28 0.940 0.357 0.028 \n",
      "\n",
      "1 0.001 sigmoid 359 0.951 0.585 0.592 \n",
      "\n",
      "1 0.0001 rbf 138 0.957 0.848 0.330 \n",
      "\n",
      "1 0.0001 sigmoid 388 0.899 0.168 0.183 \n",
      "\n",
      "10 1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "10 1 sigmoid 373 0.902 0.182 0.192 \n",
      "\n",
      "10 0.1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "10 0.1 sigmoid 340 0.904 0.171 0.163 \n",
      "\n",
      "10 0.01 rbf 35 0.939 0.343 0.034 \n",
      "\n",
      "10 0.01 sigmoid 406 0.890 0.116 0.132 \n",
      "\n",
      "10 0.001 rbf 74 0.940 0.432 0.090 \n",
      "\n",
      "10 0.001 sigmoid 360 0.953 0.597 0.606 \n",
      "\n",
      "10 0.0001 rbf 197 0.955 0.711 0.394 \n",
      "\n",
      "10 0.0001 sigmoid 370 0.906 0.216 0.225 \n",
      "\n",
      "100 1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "100 1 sigmoid 385 0.894 0.132 0.144 \n",
      "\n",
      "100 0.1 rbf 0 0.941 0.000 0.000 \n",
      "\n",
      "100 0.1 sigmoid 333 0.909 0.204 0.192 \n",
      "\n",
      "100 0.01 rbf 25 0.940 0.360 0.025 \n",
      "\n",
      "100 0.01 sigmoid 385 0.908 0.236 0.256 \n",
      "\n",
      "100 0.001 rbf 82 0.942 0.524 0.121 \n",
      "\n",
      "100 0.001 sigmoid 336 0.890 0.036 0.034 \n",
      "\n",
      "100 0.0001 rbf 260 0.954 0.650 0.476 \n",
      "\n",
      "100 0.0001 sigmoid 398 0.901 0.193 0.217 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### SVM with its Various Model Parameters\n",
    "\n",
    "features_list = \\\n",
    "['V23','V20','V17','V29','V11','V8','V2','V5','V26','V28','V22','V19','V25','V21','V9']\n",
    "\n",
    "C = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_list = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "svm_param = ['rbf', 'sigmoid'] # kernel; rbf the fastest\n",
    "# n_sample = [0.3, 0.35, 0.4, 0.5] # kernel; rbf the fastest\n",
    "\n",
    "# for ccc in C\n",
    "print \"C | gamma | svmpar | n_pred | acc | prec | recall \"\n",
    "print \"---------------------------------------------------------\" \n",
    "\n",
    "# a more hands on approach for my understanding \n",
    "# especially on which parameters having the largest impact\n",
    "for ccc in C:\n",
    "    for ggg in gamma_list:\n",
    "        for svmpar in svm_param:\n",
    "            # for nnn in n_sample:\n",
    "                # Test Size\n",
    "            features_train, features_test, labels_train, labels_test = train_test_split(X, y,\n",
    "                                                stratify=y, \n",
    "                                                test_size=0.25)\n",
    "\n",
    "            clf = SVC(kernel=svmpar, C = ccc, gamma=ggg)\n",
    "            clf.fit(features_train, labels_train)\n",
    "            predict = clf.predict(features_test)\n",
    "            acc = accuracy_score(labels_test, predict)\n",
    "            prec = precision_score(labels_test, predict)\n",
    "            recall = recall_score(labels_test, predict)\n",
    "\n",
    "            print ccc, ggg, svmpar,sum(predict),(\"{0:.3f}\".format(acc)), \\\n",
    "            (\"{0:.3f}\".format(prec)), (\"{0:.3f}\".format(recall)),\"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Based on our results, characteristics of the customers that are important to determine whether they will buy this product are: \n",
    "\n",
    "> 'V23','V20','V17','V29','V11','V8','V2','V5','V26','V28','V22','V19','V25','V21','V9'\n",
    "\n",
    "We based this on SelectKBest algorithm, which select the top k features that have maximum relvance score with y (purchase). Selection of best variables does not guarantee great prediction. We also showed examples on how different Machine Learning models and different sets of algorithm parameters arrived at different model performce.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
